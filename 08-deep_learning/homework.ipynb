{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 02:38:37.855671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-19 02:38:37.855700: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 02:38:39.021456: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-11-19 02:38:39.021485: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-19 02:38:39.021503: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist\n",
      "2023-11-19 02:38:39.021705: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "inp_shape = (150, 150, 3)\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=inp_shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Datageneeator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('data/train/',\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory('data/test/',\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=20,\n",
    "                                                        shuffle=True,\n",
    "                                                        class_mode='binary', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/184 [..............................] - ETA: 1:08 - loss: 0.6833 - acc: 0.6000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 15s 78ms/step - loss: 0.6942 - acc: 0.5344 - val_loss: 0.6747 - val_acc: 0.5414\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.6735 - acc: 0.5722 - val_loss: 0.6523 - val_acc: 0.5545\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.6593 - acc: 0.6035 - val_loss: 0.6251 - val_acc: 0.6416\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.6433 - acc: 0.6190 - val_loss: 0.6874 - val_acc: 0.5468\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.6300 - acc: 0.6413 - val_loss: 0.5938 - val_acc: 0.6972\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.5907 - acc: 0.6889 - val_loss: 0.5701 - val_acc: 0.7168\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.5514 - acc: 0.7261 - val_loss: 0.5689 - val_acc: 0.7004\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 14s 77ms/step - loss: 0.5245 - acc: 0.7425 - val_loss: 0.5727 - val_acc: 0.6906\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.4990 - acc: 0.7642 - val_loss: 0.5588 - val_acc: 0.7059\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 14s 78ms/step - loss: 0.4781 - acc: 0.7792 - val_loss: 0.5255 - val_acc: 0.7603\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6650802195072174"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_median = np.median(history.history['acc'])\n",
    "acc_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07311584656464237"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_std = np.std(history.history['loss'])\n",
    "loss_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('data/train/',\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'data/test/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 35.5214 - acc: 0.5132 - val_loss: 0.6932 - val_acc: 0.5370\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.6921 - acc: 0.5374 - val_loss: 0.6914 - val_acc: 0.5370\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.6914 - acc: 0.5374 - val_loss: 0.6908 - val_acc: 0.5370\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.6912 - acc: 0.5374 - val_loss: 0.6906 - val_acc: 0.5370\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.6904 - acc: 0.5374 - val_loss: 0.6906 - val_acc: 0.5370\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.6900 - acc: 0.5374 - val_loss: 0.6905 - val_acc: 0.5370\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.6906 - acc: 0.5374 - val_loss: 0.6904 - val_acc: 0.5370\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.6902 - acc: 0.5374 - val_loss: 0.6903 - val_acc: 0.5370\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.6902 - acc: 0.5374 - val_loss: 0.6903 - val_acc: 0.5370\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.6903 - acc: 0.5374 - val_loss: 0.6903 - val_acc: 0.5370\n"
     ]
    }
   ],
   "source": [
    "#@ MODEL TRAINING WITH AUGMENTATION:\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = history.history['val_acc']\n",
    "\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6908375501632691"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427,\n",
       " 0.5370370149612427]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5_acc = val_acc[5:10]\n",
    "last_5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5370370149612427"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(last_5_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
